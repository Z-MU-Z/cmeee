[05-04 14:13:50] INFO - ==== Train Arguments ==== {
  "output_dir": "../ckpts/bert_linear_nested_2022",
  "overwrite_output_dir": true,
  "do_train": true,
  "do_eval": true,
  "do_predict": true,
  "evaluation_strategy": "steps",
  "prediction_loss_only": false,
  "per_device_train_batch_size": 4,
  "per_device_eval_batch_size": 16,
  "per_gpu_train_batch_size": null,
  "per_gpu_eval_batch_size": null,
  "gradient_accumulation_steps": 4,
  "eval_accumulation_steps": 500,
  "eval_delay": 0,
  "learning_rate": 3e-05,
  "weight_decay": 3e-06,
  "adam_beta1": 0.9,
  "adam_beta2": 0.999,
  "adam_epsilon": 1e-08,
  "max_grad_norm": 0.5,
  "num_train_epochs": 20.0,
  "max_steps": -1,
  "lr_scheduler_type": "cosine",
  "warmup_ratio": 0.05,
  "warmup_steps": 0,
  "log_level": -1,
  "log_level_replica": -1,
  "log_on_each_node": true,
  "logging_dir": "../ckpts/bert_linear_nested_2022",
  "logging_strategy": "steps",
  "logging_first_step": true,
  "logging_steps": 200,
  "logging_nan_inf_filter": true,
  "save_strategy": "steps",
  "save_steps": 1000,
  "save_total_limit": 1,
  "save_on_each_node": false,
  "no_cuda": false,
  "seed": 2022,
  "data_seed": null,
  "bf16": false,
  "fp16": false,
  "fp16_opt_level": "O1",
  "half_precision_backend": "auto",
  "bf16_full_eval": false,
  "fp16_full_eval": false,
  "tf32": null,
  "local_rank": -1,
  "xpu_backend": null,
  "tpu_num_cores": null,
  "tpu_metrics_debug": false,
  "debug": [],
  "dataloader_drop_last": false,
  "eval_steps": 1000,
  "dataloader_num_workers": 8,
  "past_index": -1,
  "run_name": "../ckpts/bert_linear_nested_2022",
  "disable_tqdm": true,
  "remove_unused_columns": true,
  "label_names": [
    "labels",
    "labels2"
  ],
  "load_best_model_at_end": true,
  "metric_for_best_model": "f1",
  "greater_is_better": true,
  "ignore_data_skip": false,
  "sharded_ddp": [],
  "deepspeed": null,
  "label_smoothing_factor": 0.0,
  "optim": "adamw_hf",
  "adafactor": false,
  "group_by_length": false,
  "length_column_name": "length",
  "report_to": [],
  "ddp_find_unused_parameters": null,
  "ddp_bucket_cap_mb": null,
  "dataloader_pin_memory": false,
  "skip_memory_metrics": true,
  "use_legacy_prediction_loop": false,
  "push_to_hub": false,
  "resume_from_checkpoint": null,
  "hub_model_id": null,
  "hub_strategy": "every_save",
  "hub_token": "<HUB_TOKEN>",
  "gradient_checkpointing": false,
  "fp16_backend": "auto",
  "push_to_hub_model_id": null,
  "push_to_hub_organization": null,
  "push_to_hub_token": "<PUSH_TO_HUB_TOKEN>",
  "_n_gpu": 1,
  "mp_parameters": ""
}
[05-04 14:13:50] INFO - ==== Model Arguments ==== {
  "model_type": "bert",
  "head_type": "linear_nested",
  "model_path": "../bert-base-chinese",
  "init_model": 0
}
[05-04 14:13:50] INFO - ==== Data Arguments ==== {
  "cblue_root": "../data/CBLUEDatasets",
  "max_length": 512
}
[05-04 14:13:50] INFO - ===============> Called command line: 
 run_cmeee.py --output_dir ../ckpts/bert_linear_nested_2022 --report_to none --overwrite_output_dir true --do_train true --do_eval true --do_predict true --dataloader_pin_memory False --per_device_train_batch_size 4 --per_device_eval_batch_size 16 --gradient_accumulation_steps 4 --eval_accumulation_steps 500 --learning_rate 3e-5 --weight_decay 3e-6 --max_grad_norm 0.5 --lr_scheduler_type cosine --num_train_epochs 20 --warmup_ratio 0.05 --logging_dir ../ckpts/bert_linear_nested_2022 --logging_strategy steps --logging_first_step true --logging_steps 200 --save_strategy steps --save_steps 1000 --evaluation_strategy steps --eval_steps 1000 --save_total_limit 1 --no_cuda false --seed 2022 --dataloader_num_workers 8 --disable_tqdm true --load_best_model_at_end true --metric_for_best_model f1 --greater_is_better true --model_type bert --model_path ../bert-base-chinese --head_type linear_nested --cblue_root ../data/CBLUEDatasets --max_length 512 --label_names labels labels2
[05-04 14:13:50] INFO - You can copy paste it to debug
[05-04 14:14:45] INFO - Trainset: 15000 samples
[05-04 14:14:45] INFO - Devset: 5000 samples
[05-04 14:14:48] INFO - ***** Running training *****
[05-04 14:14:48] INFO -   Num examples = 15000
[05-04 14:14:48] INFO -   Num Epochs = 20
[05-04 14:14:48] INFO -   Instantaneous batch size per device = 4
[05-04 14:14:48] INFO -   Total train batch size (w. parallel, distributed & accumulation) = 16
[05-04 14:14:48] INFO -   Gradient Accumulation steps = 4
[05-04 14:14:48] INFO -   Total optimization steps = 18740
[05-04 14:16:49] INFO - ***** Running Evaluation *****
[05-04 14:16:49] INFO -   Num examples = 5000
[05-04 14:16:49] INFO -   Batch size = 16
[05-04 14:17:00] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-1000
[05-04 14:18:56] INFO - ***** Running Evaluation *****
[05-04 14:18:56] INFO -   Num examples = 5000
[05-04 14:18:56] INFO -   Batch size = 16
[05-04 14:19:06] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-2000
[05-04 14:19:08] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-1000] due to args.save_total_limit
[05-04 14:21:02] INFO - ***** Running Evaluation *****
[05-04 14:21:02] INFO -   Num examples = 5000
[05-04 14:21:02] INFO -   Batch size = 16
[05-04 14:21:13] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-3000
[05-04 14:21:14] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-2000] due to args.save_total_limit
[05-04 14:23:08] INFO - ***** Running Evaluation *****
[05-04 14:23:08] INFO -   Num examples = 5000
[05-04 14:23:08] INFO -   Batch size = 16
[05-04 14:23:19] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-4000
[05-04 14:23:21] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-3000] due to args.save_total_limit
[05-04 14:25:15] INFO - ***** Running Evaluation *****
[05-04 14:25:15] INFO -   Num examples = 5000
[05-04 14:25:15] INFO -   Batch size = 16
[05-04 14:25:26] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-5000
[05-04 14:25:27] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-4000] due to args.save_total_limit
[05-04 14:27:22] INFO - ***** Running Evaluation *****
[05-04 14:27:22] INFO -   Num examples = 5000
[05-04 14:27:22] INFO -   Batch size = 16
[05-04 14:27:32] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-6000
[05-04 14:27:34] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-5000] due to args.save_total_limit
[05-04 14:29:28] INFO - ***** Running Evaluation *****
[05-04 14:29:28] INFO -   Num examples = 5000
[05-04 14:29:28] INFO -   Batch size = 16
[05-04 14:29:39] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-7000
[05-04 14:29:41] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-6000] due to args.save_total_limit
[05-04 14:31:35] INFO - ***** Running Evaluation *****
[05-04 14:31:35] INFO -   Num examples = 5000
[05-04 14:31:35] INFO -   Batch size = 16
[05-04 14:31:45] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-8000
[05-04 14:31:47] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-7000] due to args.save_total_limit
[05-04 14:33:42] INFO - ***** Running Evaluation *****
[05-04 14:33:42] INFO -   Num examples = 5000
[05-04 14:33:42] INFO -   Batch size = 16
[05-04 14:33:52] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-9000
[05-04 14:33:54] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-8000] due to args.save_total_limit
[05-04 14:35:48] INFO - ***** Running Evaluation *****
[05-04 14:35:48] INFO -   Num examples = 5000
[05-04 14:35:48] INFO -   Batch size = 16
[05-04 14:35:59] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-10000
[05-04 14:36:00] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-9000] due to args.save_total_limit
[05-04 14:37:55] INFO - ***** Running Evaluation *****
[05-04 14:37:55] INFO -   Num examples = 5000
[05-04 14:37:55] INFO -   Batch size = 16
[05-04 14:38:06] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-11000
[05-04 14:38:08] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-10000] due to args.save_total_limit
[05-04 14:40:02] INFO - ***** Running Evaluation *****
[05-04 14:40:02] INFO -   Num examples = 5000
[05-04 14:40:02] INFO -   Batch size = 16
[05-04 14:40:13] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-12000
[05-04 14:40:14] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-11000] due to args.save_total_limit
[05-04 14:42:08] INFO - ***** Running Evaluation *****
[05-04 14:42:08] INFO -   Num examples = 5000
[05-04 14:42:08] INFO -   Batch size = 16
[05-04 14:42:19] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-13000
[05-04 14:42:21] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-12000] due to args.save_total_limit
[05-04 14:44:15] INFO - ***** Running Evaluation *****
[05-04 14:44:15] INFO -   Num examples = 5000
[05-04 14:44:15] INFO -   Batch size = 16
[05-04 14:44:25] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-14000
[05-04 14:44:27] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-13000] due to args.save_total_limit
[05-04 14:46:28] INFO - ***** Running Evaluation *****
[05-04 14:46:28] INFO -   Num examples = 5000
[05-04 14:46:28] INFO -   Batch size = 16
[05-04 14:46:38] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-15000
[05-04 14:46:40] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-14000] due to args.save_total_limit
[05-04 14:48:34] INFO - ***** Running Evaluation *****
[05-04 14:48:34] INFO -   Num examples = 5000
[05-04 14:48:34] INFO -   Batch size = 16
[05-04 14:48:45] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-16000
[05-04 14:48:46] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-15000] due to args.save_total_limit
[05-04 14:50:40] INFO - ***** Running Evaluation *****
[05-04 14:50:40] INFO -   Num examples = 5000
[05-04 14:50:40] INFO -   Batch size = 16
[05-04 14:50:51] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-17000
[05-04 14:50:53] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-16000] due to args.save_total_limit
[05-04 14:52:47] INFO - ***** Running Evaluation *****
[05-04 14:52:47] INFO -   Num examples = 5000
[05-04 14:52:47] INFO -   Batch size = 16
[05-04 14:52:58] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-18000
[05-04 14:52:59] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-17000] due to args.save_total_limit
[05-04 14:54:19] INFO - 

Training completed. Do not forget to share your model on huggingface.co/models =)


[05-04 14:54:19] INFO - Loading best model from ../ckpts/bert_linear_nested_2022/checkpoint-18000 (score: None).
[05-04 15:30:36] INFO - ==== Train Arguments ==== {
  "output_dir": "../ckpts/bert_linear_nested_2022",
  "overwrite_output_dir": true,
  "do_train": true,
  "do_eval": true,
  "do_predict": true,
  "evaluation_strategy": "steps",
  "prediction_loss_only": false,
  "per_device_train_batch_size": 4,
  "per_device_eval_batch_size": 16,
  "per_gpu_train_batch_size": null,
  "per_gpu_eval_batch_size": null,
  "gradient_accumulation_steps": 4,
  "eval_accumulation_steps": 500,
  "eval_delay": 0,
  "learning_rate": 3e-05,
  "weight_decay": 3e-06,
  "adam_beta1": 0.9,
  "adam_beta2": 0.999,
  "adam_epsilon": 1e-08,
  "max_grad_norm": 0.5,
  "num_train_epochs": 20.0,
  "max_steps": -1,
  "lr_scheduler_type": "cosine",
  "warmup_ratio": 0.05,
  "warmup_steps": 0,
  "log_level": -1,
  "log_level_replica": -1,
  "log_on_each_node": true,
  "logging_dir": "../ckpts/bert_linear_nested_2022",
  "logging_strategy": "steps",
  "logging_first_step": true,
  "logging_steps": 200,
  "logging_nan_inf_filter": true,
  "save_strategy": "steps",
  "save_steps": 1000,
  "save_total_limit": 1,
  "save_on_each_node": false,
  "no_cuda": false,
  "seed": 2022,
  "data_seed": null,
  "bf16": false,
  "fp16": false,
  "fp16_opt_level": "O1",
  "half_precision_backend": "auto",
  "bf16_full_eval": false,
  "fp16_full_eval": false,
  "tf32": null,
  "local_rank": -1,
  "xpu_backend": null,
  "tpu_num_cores": null,
  "tpu_metrics_debug": false,
  "debug": [],
  "dataloader_drop_last": false,
  "eval_steps": 1000,
  "dataloader_num_workers": 8,
  "past_index": -1,
  "run_name": "../ckpts/bert_linear_nested_2022",
  "disable_tqdm": true,
  "remove_unused_columns": true,
  "label_names": [
    "labels",
    "labels2"
  ],
  "load_best_model_at_end": true,
  "metric_for_best_model": "f1",
  "greater_is_better": true,
  "ignore_data_skip": false,
  "sharded_ddp": [],
  "deepspeed": null,
  "label_smoothing_factor": 0.0,
  "optim": "adamw_hf",
  "adafactor": false,
  "group_by_length": false,
  "length_column_name": "length",
  "report_to": [],
  "ddp_find_unused_parameters": null,
  "ddp_bucket_cap_mb": null,
  "dataloader_pin_memory": false,
  "skip_memory_metrics": true,
  "use_legacy_prediction_loop": false,
  "push_to_hub": false,
  "resume_from_checkpoint": null,
  "hub_model_id": null,
  "hub_strategy": "every_save",
  "hub_token": "<HUB_TOKEN>",
  "gradient_checkpointing": false,
  "fp16_backend": "auto",
  "push_to_hub_model_id": null,
  "push_to_hub_organization": null,
  "push_to_hub_token": "<PUSH_TO_HUB_TOKEN>",
  "_n_gpu": 1,
  "mp_parameters": ""
}
[05-04 15:30:36] INFO - ==== Model Arguments ==== {
  "model_type": "bert",
  "head_type": "linear_nested",
  "model_path": "../bert-base-chinese",
  "init_model": 0
}
[05-04 15:30:36] INFO - ==== Data Arguments ==== {
  "cblue_root": "../data/CBLUEDatasets",
  "max_length": 512
}
[05-04 15:30:36] INFO - ===============> Called command line: 
 run_cmeee.py --output_dir ../ckpts/bert_linear_nested_2022 --report_to none --overwrite_output_dir true --do_train true --do_eval true --do_predict true --dataloader_pin_memory False --per_device_train_batch_size 4 --per_device_eval_batch_size 16 --gradient_accumulation_steps 4 --eval_accumulation_steps 500 --learning_rate 3e-5 --weight_decay 3e-6 --max_grad_norm 0.5 --lr_scheduler_type cosine --num_train_epochs 20 --warmup_ratio 0.05 --logging_dir ../ckpts/bert_linear_nested_2022 --logging_strategy steps --logging_first_step true --logging_steps 200 --save_strategy steps --save_steps 1000 --evaluation_strategy steps --eval_steps 1000 --save_total_limit 1 --no_cuda false --seed 2022 --dataloader_num_workers 8 --disable_tqdm true --load_best_model_at_end true --metric_for_best_model f1 --greater_is_better true --model_type bert --model_path ../bert-base-chinese --head_type linear_nested --cblue_root ../data/CBLUEDatasets --max_length 512 --label_names labels labels2
[05-04 15:30:36] INFO - You can copy paste it to debug
[05-04 15:31:32] INFO - Trainset: 15000 samples
[05-04 15:31:32] INFO - Devset: 5000 samples
[05-04 15:31:35] INFO - ***** Running training *****
[05-04 15:31:35] INFO -   Num examples = 15000
[05-04 15:31:35] INFO -   Num Epochs = 20
[05-04 15:31:35] INFO -   Instantaneous batch size per device = 4
[05-04 15:31:35] INFO -   Total train batch size (w. parallel, distributed & accumulation) = 16
[05-04 15:31:35] INFO -   Gradient Accumulation steps = 4
[05-04 15:31:35] INFO -   Total optimization steps = 18740
[05-04 15:33:36] INFO - ***** Running Evaluation *****
[05-04 15:33:36] INFO -   Num examples = 5000
[05-04 15:33:36] INFO -   Batch size = 16
[05-04 15:33:47] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-1000
[05-04 15:33:49] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-18000] due to args.save_total_limit
[05-04 15:34:28] INFO - Keyboard interrupt
[05-04 15:34:31] INFO - Testset: 3000 samples
[05-04 15:34:31] INFO - ***** Running Prediction *****
[05-04 15:34:31] INFO -   Num examples = 3000
[05-04 15:34:31] INFO -   Batch size = 16
[05-04 15:34:34] INFO - `CMeEE_test.json` saved
[05-04 17:26:44] INFO - ==== Train Arguments ==== {
  "output_dir": "../ckpts/bert_linear_nested_2022",
  "overwrite_output_dir": true,
  "do_train": true,
  "do_eval": true,
  "do_predict": true,
  "evaluation_strategy": "steps",
  "prediction_loss_only": false,
  "per_device_train_batch_size": 4,
  "per_device_eval_batch_size": 16,
  "per_gpu_train_batch_size": null,
  "per_gpu_eval_batch_size": null,
  "gradient_accumulation_steps": 4,
  "eval_accumulation_steps": 500,
  "eval_delay": 0,
  "learning_rate": 3e-05,
  "weight_decay": 3e-06,
  "adam_beta1": 0.9,
  "adam_beta2": 0.999,
  "adam_epsilon": 1e-08,
  "max_grad_norm": 0.5,
  "num_train_epochs": 20.0,
  "max_steps": -1,
  "lr_scheduler_type": "cosine",
  "warmup_ratio": 0.05,
  "warmup_steps": 0,
  "log_level": -1,
  "log_level_replica": -1,
  "log_on_each_node": true,
  "logging_dir": "../ckpts/bert_linear_nested_2022",
  "logging_strategy": "steps",
  "logging_first_step": true,
  "logging_steps": 200,
  "logging_nan_inf_filter": true,
  "save_strategy": "steps",
  "save_steps": 1000,
  "save_total_limit": 1,
  "save_on_each_node": false,
  "no_cuda": false,
  "seed": 2022,
  "data_seed": null,
  "bf16": false,
  "fp16": false,
  "fp16_opt_level": "O1",
  "half_precision_backend": "auto",
  "bf16_full_eval": false,
  "fp16_full_eval": false,
  "tf32": null,
  "local_rank": -1,
  "xpu_backend": null,
  "tpu_num_cores": null,
  "tpu_metrics_debug": false,
  "debug": [],
  "dataloader_drop_last": false,
  "eval_steps": 1000,
  "dataloader_num_workers": 8,
  "past_index": -1,
  "run_name": "../ckpts/bert_linear_nested_2022",
  "disable_tqdm": true,
  "remove_unused_columns": true,
  "label_names": [
    "labels",
    "labels2"
  ],
  "load_best_model_at_end": true,
  "metric_for_best_model": "f1",
  "greater_is_better": true,
  "ignore_data_skip": false,
  "sharded_ddp": [],
  "deepspeed": null,
  "label_smoothing_factor": 0.0,
  "optim": "adamw_hf",
  "adafactor": false,
  "group_by_length": false,
  "length_column_name": "length",
  "report_to": [],
  "ddp_find_unused_parameters": null,
  "ddp_bucket_cap_mb": null,
  "dataloader_pin_memory": false,
  "skip_memory_metrics": true,
  "use_legacy_prediction_loop": false,
  "push_to_hub": false,
  "resume_from_checkpoint": null,
  "hub_model_id": null,
  "hub_strategy": "every_save",
  "hub_token": "<HUB_TOKEN>",
  "gradient_checkpointing": false,
  "fp16_backend": "auto",
  "push_to_hub_model_id": null,
  "push_to_hub_organization": null,
  "push_to_hub_token": "<PUSH_TO_HUB_TOKEN>",
  "_n_gpu": 1,
  "mp_parameters": ""
}
[05-04 17:26:44] INFO - ==== Model Arguments ==== {
  "model_type": "bert",
  "head_type": "linear_nested",
  "model_path": "../bert-base-chinese",
  "init_model": 0
}
[05-04 17:26:44] INFO - ==== Data Arguments ==== {
  "cblue_root": "../data/CBLUEDatasets",
  "max_length": 512
}
[05-04 17:26:44] INFO - ===============> Called command line: 
 run_cmeee.py --output_dir ../ckpts/bert_linear_nested_2022 --report_to none --overwrite_output_dir true --do_train true --do_eval true --do_predict true --dataloader_pin_memory False --per_device_train_batch_size 4 --per_device_eval_batch_size 16 --gradient_accumulation_steps 4 --eval_accumulation_steps 500 --learning_rate 3e-5 --weight_decay 3e-6 --max_grad_norm 0.5 --lr_scheduler_type cosine --num_train_epochs 20 --warmup_ratio 0.05 --logging_dir ../ckpts/bert_linear_nested_2022 --logging_strategy steps --logging_first_step true --logging_steps 200 --save_strategy steps --save_steps 1000 --evaluation_strategy steps --eval_steps 1000 --save_total_limit 1 --no_cuda false --seed 2022 --dataloader_num_workers 8 --disable_tqdm true --load_best_model_at_end true --metric_for_best_model f1 --greater_is_better true --model_type bert --model_path ../bert-base-chinese --head_type linear_nested --cblue_root ../data/CBLUEDatasets --max_length 512 --label_names labels labels2
[05-04 17:26:44] INFO - You can copy paste it to debug
[05-04 17:27:39] INFO - Trainset: 15000 samples
[05-04 17:27:39] INFO - Devset: 5000 samples
[05-04 17:27:43] INFO - ***** Running training *****
[05-04 17:27:43] INFO -   Num examples = 15000
[05-04 17:27:43] INFO -   Num Epochs = 20
[05-04 17:27:43] INFO -   Instantaneous batch size per device = 4
[05-04 17:27:43] INFO -   Total train batch size (w. parallel, distributed & accumulation) = 16
[05-04 17:27:43] INFO -   Gradient Accumulation steps = 4
[05-04 17:27:43] INFO -   Total optimization steps = 18740
[05-04 17:29:29] INFO - ***** Running Evaluation *****
[05-04 17:29:29] INFO -   Num examples = 5000
[05-04 17:29:29] INFO -   Batch size = 16
[05-04 17:29:35] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-1000
[05-04 17:31:23] INFO - ***** Running Evaluation *****
[05-04 17:31:23] INFO -   Num examples = 5000
[05-04 17:31:23] INFO -   Batch size = 16
[05-04 17:31:28] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-2000
[05-04 17:31:30] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-1000] due to args.save_total_limit
[05-04 17:33:15] INFO - ***** Running Evaluation *****
[05-04 17:33:15] INFO -   Num examples = 5000
[05-04 17:33:15] INFO -   Batch size = 16
[05-04 17:33:21] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-3000
[05-04 17:33:22] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-2000] due to args.save_total_limit
[05-04 17:35:09] INFO - ***** Running Evaluation *****
[05-04 17:35:09] INFO -   Num examples = 5000
[05-04 17:35:09] INFO -   Batch size = 16
[05-04 17:35:14] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-4000
[05-04 17:35:16] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-3000] due to args.save_total_limit
[05-04 17:37:02] INFO - ***** Running Evaluation *****
[05-04 17:37:02] INFO -   Num examples = 5000
[05-04 17:37:02] INFO -   Batch size = 16
[05-04 17:37:07] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-5000
[05-04 17:38:56] INFO - ***** Running Evaluation *****
[05-04 17:38:56] INFO -   Num examples = 5000
[05-04 17:38:56] INFO -   Batch size = 16
[05-04 17:39:02] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-6000
[05-04 17:39:03] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-5000] due to args.save_total_limit
[05-04 17:40:49] INFO - ***** Running Evaluation *****
[05-04 17:40:49] INFO -   Num examples = 5000
[05-04 17:40:49] INFO -   Batch size = 16
[05-04 17:40:54] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-7000
[05-04 17:40:56] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-4000] due to args.save_total_limit
[05-04 17:40:56] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-6000] due to args.save_total_limit
[05-04 17:42:42] INFO - ***** Running Evaluation *****
[05-04 17:42:42] INFO -   Num examples = 5000
[05-04 17:42:42] INFO -   Batch size = 16
[05-04 17:42:48] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-8000
[05-04 17:42:50] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-7000] due to args.save_total_limit
[05-04 17:44:35] INFO - ***** Running Evaluation *****
[05-04 17:44:35] INFO -   Num examples = 5000
[05-04 17:44:35] INFO -   Batch size = 16
[05-04 17:44:41] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-9000
[05-04 17:46:29] INFO - ***** Running Evaluation *****
[05-04 17:46:29] INFO -   Num examples = 5000
[05-04 17:46:29] INFO -   Batch size = 16
[05-04 17:46:34] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-10000
[05-04 17:46:35] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-9000] due to args.save_total_limit
[05-04 17:48:21] INFO - ***** Running Evaluation *****
[05-04 17:48:21] INFO -   Num examples = 5000
[05-04 17:48:21] INFO -   Batch size = 16
[05-04 17:48:26] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-11000
[05-04 17:48:28] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-10000] due to args.save_total_limit
[05-04 17:50:14] INFO - ***** Running Evaluation *****
[05-04 17:50:14] INFO -   Num examples = 5000
[05-04 17:50:14] INFO -   Batch size = 16
[05-04 17:50:19] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-12000
[05-04 17:50:20] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-8000] due to args.save_total_limit
[05-04 17:50:20] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-11000] due to args.save_total_limit
[05-04 17:52:06] INFO - ***** Running Evaluation *****
[05-04 17:52:06] INFO -   Num examples = 5000
[05-04 17:52:06] INFO -   Batch size = 16
[05-04 17:52:11] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-13000
[05-04 17:52:13] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-12000] due to args.save_total_limit
[05-04 17:53:59] INFO - ***** Running Evaluation *****
[05-04 17:53:59] INFO -   Num examples = 5000
[05-04 17:53:59] INFO -   Batch size = 16
[05-04 17:54:04] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-14000
[05-04 17:55:53] INFO - ***** Running Evaluation *****
[05-04 17:55:53] INFO -   Num examples = 5000
[05-04 17:55:53] INFO -   Batch size = 16
[05-04 17:55:58] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-15000
[05-04 17:56:00] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-13000] due to args.save_total_limit
[05-04 17:56:00] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-14000] due to args.save_total_limit
[05-04 17:57:46] INFO - ***** Running Evaluation *****
[05-04 17:57:46] INFO -   Num examples = 5000
[05-04 17:57:46] INFO -   Batch size = 16
[05-04 17:57:51] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-16000
[05-04 17:59:39] INFO - ***** Running Evaluation *****
[05-04 17:59:39] INFO -   Num examples = 5000
[05-04 17:59:39] INFO -   Batch size = 16
[05-04 17:59:44] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-17000
[05-04 17:59:48] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-16000] due to args.save_total_limit
[05-04 18:01:34] INFO - ***** Running Evaluation *****
[05-04 18:01:34] INFO -   Num examples = 5000
[05-04 18:01:34] INFO -   Batch size = 16
[05-04 18:01:40] INFO - Saving model checkpoint to ../ckpts/bert_linear_nested_2022/checkpoint-18000
[05-04 18:01:42] INFO - Deleting older checkpoint [../ckpts/bert_linear_nested_2022/checkpoint-17000] due to args.save_total_limit
[05-04 18:03:00] INFO - 

Training completed. Do not forget to share your model on huggingface.co/models =)


[05-04 18:03:00] INFO - Loading best model from ../ckpts/bert_linear_nested_2022/checkpoint-15000 (score: 0.6227889757301522).
[05-04 18:03:06] INFO - Testset: 3000 samples
[05-04 18:03:06] INFO - ***** Running Prediction *****
[05-04 18:03:06] INFO -   Num examples = 3000
[05-04 18:03:06] INFO -   Batch size = 16
[05-04 18:03:08] INFO - `CMeEE_test.json` saved
